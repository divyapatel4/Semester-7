{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IE406 Machine Learning \n",
    "## Lab Assignment 6: Principal Component Analysis\n",
    "\n",
    "---\n",
    "\n",
    "### Devdeep Shetrajiwala : 202001150\n",
    "\n",
    "### Divya Patel : 202001420\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n7DKntvhX-iT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import h5py\n",
    "from sklearn.datasets import fetch_openml\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woiJGVgka21e"
   },
   "source": [
    "## Question 1\n",
    "\n",
    "Given the following data use Principal Component Analysis to reduce the feature\n",
    "dimension from 3 to 1 also show eigen values. (Do manual calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BkWlVJzubUWB",
    "outputId": "ef322ac1-d15b-4b46-d49a-9ec0e43b18cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance ratio:  [0.49991964]\n",
      "\n",
      "\n",
      "The first principal component is: \n",
      "   principal component 1\n",
      "0              -0.204236\n",
      "1              -0.586974\n",
      "2               1.740811\n",
      "3              -0.710952\n",
      "4              -1.708027\n",
      "5               1.469378\n",
      "\n",
      "\n",
      "The eigenvalues after the dimension reduction by PCA of the given data are :\n",
      "[[-0.69401025  0.16586365  0.70059904]]\n"
     ]
    }
   ],
   "source": [
    "# defining required array\n",
    "X = np.array([[8,14,3],[13,9,6],[4,3,15],[7,2,1],[19,8,4],[5,18,11]])\n",
    "\n",
    "# standard scaler to make mean 0 and variance 1\n",
    "sc = StandardScaler()\n",
    "X_std = sc.fit_transform(X)\n",
    "\n",
    "# performing PCA\n",
    "pca = PCA(n_components =1)\n",
    "principalComponent = pca.fit_transform(X_std)\n",
    "pComponents = pd.DataFrame(data = principalComponent , columns = ['principal component 1'])\n",
    "\n",
    "# printing the variance ratio of each component \n",
    "print(\"Variance ratio: \", pca.explained_variance_ratio_)\n",
    "\n",
    "print (\"\\n\\nThe first principal component is: \")\n",
    "print(pComponents)\n",
    "\n",
    "print (\"\\n\\nThe eigenvalues after the dimension reduction by PCA of the given data are :\")\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5EuAiE_VfsVY",
    "outputId": "76acb426-9264-45aa-af90-2093e5b7a0ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2        -0.04772727 -0.58277152]\n",
      " [-0.04772727  1.2         0.09470037]\n",
      " [-0.58277152  0.09470037  1.2       ]]\n"
     ]
    }
   ],
   "source": [
    "def computePCA(X):\n",
    "  scaler = StandardScaler()\n",
    "  X_scaled = scaler.fit_transform(X)\n",
    "  means = np.mean(X_scaled, axis = 0)\n",
    "  covariance_matrix=(X_scaled-means).T.dot((X_scaled-means))/(X_scaled.shape[0]-1)\n",
    "  print(covariance_matrix)\n",
    "  eigen_vals,eigen_vectors=np.linalg.eig(covariance_matrix)\n",
    "  return [eigen_vals, eigen_vectors, X_scaled]\n",
    "eig_vals, eig_vectors, X_scaled = computePCA(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHdcPGpKf_i8",
    "outputId": "ca898acf-ee6e-45ea-8d3e-7d2f4f1b1de3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eigen Values = [1.79971072 0.61531314 1.18497614]\n",
      "[-0.69401025  0.16586365  0.70059904]\n",
      "[-0.20423593 -0.58697404  1.74081123 -0.71095189 -1.70802694  1.46937756]\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nEigen Values = {eig_vals}')\n",
    "print(eig_vectors[: , 0])\n",
    "final_feature=(X_scaled).dot(eig_vectors[: , 0])\n",
    "print(final_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigen Vectors :\n",
      " [[ 0.65370829  0.70071725 -0.28576354]\n",
      " [-0.04563208 -0.34043372 -0.93916058]\n",
      " [ 0.75536957 -0.62697704  0.19056916]] \n",
      "\n",
      "Eigen Values :\n",
      " [15.41684401 46.07005232 37.44643701] \n",
      "\n",
      "[[-3.86945988 -0.33754247 -5.01353842]\n",
      " [ 1.89335068  2.98728129 -1.17484576]\n",
      " [ 3.08209469 -6.91936503  8.74711203]\n",
      " [-5.48632232  4.30089903  6.16101375]\n",
      " [ 4.35049337  8.78597262 -2.33140475]\n",
      " [ 0.02984346 -8.81724545 -6.38833684]]\n"
     ]
    }
   ],
   "source": [
    "#MANUAL CALCULATION\n",
    "from numpy import mean\n",
    "from numpy import cov\n",
    "from numpy import array\n",
    "from numpy.linalg import eig\n",
    "\n",
    "# calculating the mean of each column\n",
    "Mean = mean(X.T, axis=1)\n",
    "\n",
    "# determining center columns by subtracting column means\n",
    "X_STD = X - Mean\n",
    "\n",
    "# calculating covariance matrix of centered matrix\n",
    "Va = cov(X_STD.T)\n",
    "\n",
    "# eigendecomposition of covariance matrix\n",
    "values, vectors = eig(Va)\n",
    "print(\"Eigen Vectors :\\n\",vectors,'\\n')\n",
    "print(\"Eigen Values :\\n\",values,'\\n')\n",
    "\n",
    "# projectnig the data\n",
    "Prj = vectors.T.dot(X_STD.T)\n",
    "print(Prj.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pk6MWyDTgDuN"
   },
   "source": [
    "## Question 2\n",
    "\n",
    "A classic application of PCA is to project the 3-D point cloud onto a plane that could still retain the information or essence of the point distribution. Given a 3-D point cloud, estimate an optimal plane, onto which if the 3D data points when projected would still retain the essential information. We provide you with 5 different point clouds P_1.txt to P_5.txt containing the 3D coordinates of points in space. Perform PCA on these point clouds to obtain their projection on a 2D plane and visualize the results using python libraries (like matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BX8gKSl5gNR2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
